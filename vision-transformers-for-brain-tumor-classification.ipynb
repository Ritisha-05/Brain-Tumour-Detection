{"cells":[{"cell_type":"code","execution_count":53,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-07-06T08:28:31.816072Z","iopub.status.busy":"2022-07-06T08:28:31.815332Z","iopub.status.idle":"2022-07-06T08:28:41.804940Z","shell.execute_reply":"2022-07-06T08:28:41.803377Z","shell.execute_reply.started":"2022-07-06T08:28:31.816023Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tensorflow-addons in /opt/conda/lib/python3.7/site-packages (0.14.0)\n","Requirement already satisfied: typeguard>=2.7 in /opt/conda/lib/python3.7/site-packages (from tensorflow-addons) (2.13.3)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["! pip install tensorflow-addons"]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2022-07-06T08:28:41.808269Z","iopub.status.busy":"2022-07-06T08:28:41.807839Z","iopub.status.idle":"2022-07-06T08:28:41.816338Z","shell.execute_reply":"2022-07-06T08:28:41.815272Z","shell.execute_reply.started":"2022-07-06T08:28:41.808218Z"},"trusted":true},"outputs":[],"source":["import os\n","import math\n","import numpy as np\n","from tensorflow import keras\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import tensorflow_addons as tfa\n","from tensorflow.keras import layers\n","import numpy as np\n","from sklearn.utils import shuffle\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","from PIL import Image, ImageEnhance\n","from tqdm import tqdm\n","import os\n","import random\n","import cv2"]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2022-07-06T08:28:41.818393Z","iopub.status.busy":"2022-07-06T08:28:41.818067Z","iopub.status.idle":"2022-07-06T08:28:41.827604Z","shell.execute_reply":"2022-07-06T08:28:41.826543Z","shell.execute_reply.started":"2022-07-06T08:28:41.818364Z"},"trusted":true},"outputs":[],"source":["labels = {'glioma':0,'notumor':1,'meningioma':2,'pituitary':3}"]},{"cell_type":"code","execution_count":57,"metadata":{"execution":{"iopub.execute_input":"2022-07-06T08:28:58.204828Z","iopub.status.busy":"2022-07-06T08:28:58.204120Z","iopub.status.idle":"2022-07-06T08:29:21.515907Z","shell.execute_reply":"2022-07-06T08:29:21.514474Z","shell.execute_reply.started":"2022-07-06T08:28:58.204767Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1321/1321 [00:04<00:00, 302.43it/s]\n","100%|██████████| 1595/1595 [00:04<00:00, 370.03it/s]\n","100%|██████████| 1339/1339 [00:04<00:00, 274.49it/s]\n","100%|██████████| 1457/1457 [00:05<00:00, 261.68it/s]\n","100%|██████████| 300/300 [00:01<00:00, 298.06it/s]\n","100%|██████████| 405/405 [00:00<00:00, 458.32it/s]\n","100%|██████████| 306/306 [00:00<00:00, 313.60it/s]\n","100%|██████████| 300/300 [00:01<00:00, 275.31it/s]\n"]}],"source":["x_train = []\n","y_train = []\n","image_size = 150\n","for i in labels:\n","    folderPath = os.path.join('../input/brain-tumor-mri-dataset/Training',i)\n","    for j in tqdm(os.listdir(folderPath)):\n","        img = cv2.imread(os.path.join(folderPath,j))\n","        img = cv2.resize(img,(image_size, image_size))\n","        x_train.append(img)\n","        y_train.append(labels[i])\n","        \n","for i in labels:\n","    folderPath = os.path.join('../input/brain-tumor-mri-dataset/Testing',i)\n","    for j in tqdm(os.listdir(folderPath)):\n","        img = cv2.imread(os.path.join(folderPath,j))\n","        img = cv2.resize(img,(image_size,image_size))\n","        x_train.append(img)\n","        y_train.append(labels[i])\n","        \n","x_train = np.array(x_train)\n","y_train = np.array(y_train)"]},{"cell_type":"code","execution_count":58,"metadata":{"execution":{"iopub.execute_input":"2022-07-06T08:29:30.510506Z","iopub.status.busy":"2022-07-06T08:29:30.509879Z","iopub.status.idle":"2022-07-06T08:29:30.722573Z","shell.execute_reply":"2022-07-06T08:29:30.721356Z","shell.execute_reply.started":"2022-07-06T08:29:30.510457Z"},"trusted":true},"outputs":[],"source":["x_train, y_train = shuffle(x_train,y_train, random_state=101)"]},{"cell_type":"code","execution_count":59,"metadata":{"execution":{"iopub.execute_input":"2022-07-06T08:29:33.570024Z","iopub.status.busy":"2022-07-06T08:29:33.569631Z","iopub.status.idle":"2022-07-06T08:29:33.683281Z","shell.execute_reply":"2022-07-06T08:29:33.681693Z","shell.execute_reply.started":"2022-07-06T08:29:33.569993Z"},"trusted":true},"outputs":[],"source":["x_train,x_test,y_train,y_test = train_test_split(x_train,y_train, test_size=0.1,random_state=101)"]},{"cell_type":"code","execution_count":60,"metadata":{"execution":{"iopub.execute_input":"2022-07-06T08:29:36.100143Z","iopub.status.busy":"2022-07-06T08:29:36.099688Z","iopub.status.idle":"2022-07-06T08:29:36.107560Z","shell.execute_reply":"2022-07-06T08:29:36.106220Z","shell.execute_reply.started":"2022-07-06T08:29:36.100110Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[1 2 3 ... 3 0 0]\n"]}],"source":["print(y_train)"]},{"cell_type":"code","execution_count":73,"metadata":{"execution":{"iopub.execute_input":"2022-07-06T08:37:55.250473Z","iopub.status.busy":"2022-07-06T08:37:55.250002Z","iopub.status.idle":"2022-07-06T08:37:55.259694Z","shell.execute_reply":"2022-07-06T08:37:55.258093Z","shell.execute_reply.started":"2022-07-06T08:37:55.250440Z"},"trusted":true},"outputs":[],"source":["# DATA\n","NUM_CLASSES = 4\n","INPUT_SHAPE = (32, 32, 3)\n","BUFFER_SIZE = 512\n","BATCH_SIZE = 256\n","\n","# AUGMENTATION\n","IMAGE_SIZE = 72\n","PATCH_SIZE = 6\n","NUM_PATCHES = (IMAGE_SIZE // PATCH_SIZE) ** 2\n","\n","# OPTIMIZER\n","LEARNING_RATE = 0.001\n","WEIGHT_DECAY = 0.0001\n","\n","# TRAINING\n","EPOCHS = 10\n","\n","# ARCHITECTURE\n","LAYER_NORM_EPS = 1e-6\n","TRANSFORMER_LAYERS = 8\n","PROJECTION_DIM = 64\n","NUM_HEADS = 4\n","TRANSFORMER_UNITS = [\n","    PROJECTION_DIM * 2,\n","    PROJECTION_DIM,\n","]\n","MLP_HEAD_UNITS = [\n","    2048,\n","    1024\n","]"]},{"cell_type":"code","execution_count":62,"metadata":{"execution":{"iopub.execute_input":"2022-07-06T08:29:40.725290Z","iopub.status.busy":"2022-07-06T08:29:40.724866Z","iopub.status.idle":"2022-07-06T08:29:48.309814Z","shell.execute_reply":"2022-07-06T08:29:48.308621Z","shell.execute_reply.started":"2022-07-06T08:29:40.725229Z"},"trusted":true},"outputs":[],"source":["train_data_augmentation = keras.Sequential(\n","    [\n","        layers.Normalization(),\n","        layers.Resizing(IMAGE_SIZE, IMAGE_SIZE),\n","        layers.RandomFlip(\"horizontal\"),\n","        layers.RandomRotation(factor=0.02),\n","        layers.RandomZoom(\n","            height_factor=0.2, width_factor=0.2\n","        ),\n","    ],\n","    name=\"train_data_augmentation\",\n",")\n","\n","test_data_augmentation = keras.Sequential(\n","    [\n","        layers.Normalization(),\n","        layers.Resizing(IMAGE_SIZE, IMAGE_SIZE),\n","    ],\n","    name=\"test_data_augmentation\",\n",")\n","\n","# Compute the mean and the variance of the training data for normalization.\n","train_data_augmentation.layers[0].adapt(x_train)\n","test_data_augmentation.layers[0].adapt(x_train)"]},{"cell_type":"code","execution_count":63,"metadata":{"execution":{"iopub.execute_input":"2022-07-06T08:29:48.311951Z","iopub.status.busy":"2022-07-06T08:29:48.311609Z","iopub.status.idle":"2022-07-06T08:29:48.317840Z","shell.execute_reply":"2022-07-06T08:29:48.316682Z","shell.execute_reply.started":"2022-07-06T08:29:48.311920Z"},"trusted":true},"outputs":[],"source":["def map_fn_train(image, label):\n","    return (train_data_augmentation(image), label)\n","\n","def map_fn_test(image, label):\n","    return (test_data_augmentation(image), label)"]},{"cell_type":"code","execution_count":64,"metadata":{"execution":{"iopub.execute_input":"2022-07-06T08:29:51.414675Z","iopub.status.busy":"2022-07-06T08:29:51.414299Z","iopub.status.idle":"2022-07-06T08:29:51.920874Z","shell.execute_reply":"2022-07-06T08:29:51.919818Z","shell.execute_reply.started":"2022-07-06T08:29:51.414645Z"},"trusted":true},"outputs":[],"source":["AUTO = tf.data.AUTOTUNE\n","train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n","train_ds = train_ds.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).map(map_fn_train).prefetch(AUTO)\n","\n","\n","test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n","test_ds = test_ds.batch(BATCH_SIZE).map(map_fn_test).prefetch(AUTO)"]},{"cell_type":"code","execution_count":65,"metadata":{"execution":{"iopub.execute_input":"2022-07-06T08:29:54.133940Z","iopub.status.busy":"2022-07-06T08:29:54.132769Z","iopub.status.idle":"2022-07-06T08:29:54.151497Z","shell.execute_reply":"2022-07-06T08:29:54.149641Z","shell.execute_reply.started":"2022-07-06T08:29:54.133894Z"},"trusted":true},"outputs":[],"source":["class ShiftedPatchTokenization(layers.Layer):\n","    def __init__(\n","        self,\n","        image_size=IMAGE_SIZE,\n","        patch_size=PATCH_SIZE,\n","        num_patches=NUM_PATCHES,\n","        projection_dim=PROJECTION_DIM,\n","        vanilla=False,\n","    ):\n","        super().__init__()\n","        self.vanilla = vanilla # Flag to swtich to vanilla patch extractor\n","        self.image_size = image_size\n","        self.patch_size = patch_size\n","        self.half_patch = patch_size // 2\n","        self.flatten_patches = layers.Reshape((num_patches, -1))\n","        self.projection = layers.Dense(units=projection_dim)\n","        self.layer_norm = layers.LayerNormalization(epsilon=LAYER_NORM_EPS)\n","    \n","    def get_config(self):\n","        config = super().get_config()\n","        config.update({\n","            \"vanilla\": self.vanilla,\n","            \"image_size\": self.image_size,\n","            \"patch_size\": self.patch_size,\n","            \"half_patch\": self.half_patch\n","        })\n","        return config\n","    \n","    def crop_shift_pad(self, images, mode):\n","        # Build the diagonally shifted images\n","        if mode == \"left-up\":\n","            crop_height = self.half_patch\n","            crop_width = self.half_patch\n","            shift_height = 0\n","            shift_width = 0\n","        elif mode == \"left-down\":\n","            crop_height = 0\n","            crop_width = self.half_patch\n","            shift_height = self.half_patch\n","            shift_width = 0\n","        elif mode == \"right-up\":\n","            crop_height = self.half_patch\n","            crop_width = 0\n","            shift_height = 0\n","            shift_width = self.half_patch\n","        else:\n","            crop_height = 0\n","            crop_width = 0\n","            shift_height = self.half_patch\n","            shift_width = self.half_patch\n","        \n","        # Crop the shifted images and pad them\n","        crop = tf.image.crop_to_bounding_box(\n","            images,\n","            offset_height=crop_height,\n","            offset_width=crop_width,\n","            target_height=self.image_size-self.half_patch,\n","            target_width=self.image_size-self.half_patch,\n","        )\n","        shift_pad = tf.image.pad_to_bounding_box(\n","            crop,\n","            offset_height=shift_height,\n","            offset_width=shift_width,\n","            target_height=self.image_size,\n","            target_width=self.image_size,\n","        )\n","        return shift_pad\n","\n","    def call(self, images):\n","        if not self.vanilla:\n","            # Concat the shifted images with the original image\n","            images = tf.concat(\n","                [\n","                    images,\n","                    self.crop_shift_pad(images, mode=\"left-up\"),\n","                    self.crop_shift_pad(images, mode=\"left-down\"),\n","                    self.crop_shift_pad(images, mode=\"right-up\"),\n","                    self.crop_shift_pad(images, mode=\"right-down\"),\n","                ],\n","                axis=-1\n","            )\n","        # Patchify the images and flatten it\n","        patches = tf.image.extract_patches(\n","            images=images,\n","            sizes=[1, self.patch_size, self.patch_size, 1],\n","            strides=[1, self.patch_size, self.patch_size, 1],\n","            rates=[1, 1, 1, 1],\n","            padding=\"VALID\",\n","        )\n","        flat_patches = self.flatten_patches(patches)\n","        if not self.vanilla:\n","            # Layer normalize the flat patches and linearly project it\n","            tokens = self.layer_norm(flat_patches)\n","            tokens = self.projection(tokens)\n","        else:\n","            # Linearly project the flat patches\n","            tokens = self.projection(flat_patches)\n","        return (tokens, patches)"]},{"cell_type":"code","execution_count":66,"metadata":{"execution":{"iopub.execute_input":"2022-07-06T08:30:00.315679Z","iopub.status.busy":"2022-07-06T08:30:00.315200Z","iopub.status.idle":"2022-07-06T08:30:00.325777Z","shell.execute_reply":"2022-07-06T08:30:00.324693Z","shell.execute_reply.started":"2022-07-06T08:30:00.315645Z"},"trusted":true},"outputs":[],"source":["class PatchEncoder(layers.Layer):\n","    def __init__(self, num_patches=NUM_PATCHES, projection_dim=PROJECTION_DIM):\n","        super().__init__()\n","        self.num_patches = num_patches\n","        self.position_embedding = layers.Embedding(\n","            input_dim=num_patches, output_dim=projection_dim\n","        )\n","        self.positions = tf.range(start=0, limit=self.num_patches, delta=1)\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update({\n","            \"num_patches\": self.num_patches,\n","            \"positions\": self.positions.numpy(),\n","        })\n","        return config\n","\n","    def call(self, encoded_patches):\n","        encoded_positions = self.position_embedding(self.positions)\n","        encoded_patches = encoded_patches + encoded_positions\n","        return encoded_patches"]},{"cell_type":"code","execution_count":67,"metadata":{"execution":{"iopub.execute_input":"2022-07-06T08:30:03.506201Z","iopub.status.busy":"2022-07-06T08:30:03.505776Z","iopub.status.idle":"2022-07-06T08:30:03.516485Z","shell.execute_reply":"2022-07-06T08:30:03.514543Z","shell.execute_reply.started":"2022-07-06T08:30:03.506168Z"},"trusted":true},"outputs":[],"source":["class MultiHeadAttentionLSA(tf.keras.layers.MultiHeadAttention):\n","    def __init__(self, **kwargs):\n","        super().__init__(**kwargs)\n","        # The trainable temperature term. The initial value is\n","        # the square root of the key dimension.\n","        self.tau = tf.Variable(\n","            math.sqrt(float(self._key_dim)),\n","            trainable=True\n","        )\n","        # Build the diagonal attention mask\n","        diag_attn_mask = 1 - tf.eye(NUM_PATCHES)\n","        self.diag_attn_mask = tf.cast([diag_attn_mask], dtype=tf.int8)\n","    \n","    def get_config(self):\n","        config = super().get_config()\n","        config.update({\n","            \"tau\": self.tau.numpy(),\n","            \"diag_attn_mask\": self.diag_attn_mask.numpy(),\n","        })\n","        return config\n","\n","    def _compute_attention(\n","        self,\n","        query,\n","        key,\n","        value,\n","        attention_mask=None,\n","        training=None\n","    ):\n","        query = tf.multiply(query, 1.0 / self.tau)\n","        attention_scores = tf.einsum(self._dot_product_equation, key, query)\n","        attention_scores = self._masked_softmax(attention_scores, attention_mask=self.diag_attn_mask)\n","        attention_scores_dropout = self._dropout_layer(attention_scores, training=training)\n","        attention_output = tf.einsum(self._combine_equation, attention_scores_dropout, value)\n","        return attention_output, attention_scores"]},{"cell_type":"code","execution_count":68,"metadata":{"execution":{"iopub.execute_input":"2022-07-06T08:30:06.149552Z","iopub.status.busy":"2022-07-06T08:30:06.149046Z","iopub.status.idle":"2022-07-06T08:30:06.157280Z","shell.execute_reply":"2022-07-06T08:30:06.155240Z","shell.execute_reply.started":"2022-07-06T08:30:06.149511Z"},"trusted":true},"outputs":[],"source":["def mlp(x, hidden_units, dropout_rate):\n","    for units in hidden_units:\n","        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n","        x = layers.Dropout(dropout_rate)(x)\n","    return x"]},{"cell_type":"code","execution_count":69,"metadata":{"execution":{"iopub.execute_input":"2022-07-06T08:30:09.993035Z","iopub.status.busy":"2022-07-06T08:30:09.992619Z","iopub.status.idle":"2022-07-06T08:30:10.006797Z","shell.execute_reply":"2022-07-06T08:30:10.005941Z","shell.execute_reply.started":"2022-07-06T08:30:09.993004Z"},"trusted":true},"outputs":[],"source":["def create_vit_classifier(vanilla=False):\n","    inputs = layers.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3), name=\"input_layer\")\n","    # Create patches.\n","    (tokens, _)  = ShiftedPatchTokenization(vanilla=vanilla)(inputs)\n","    # Encode patches.\n","    encoded_patches = PatchEncoder()(tokens)\n","\n","    # Create multiple layers of the Transformer block.\n","    for _ in range(TRANSFORMER_LAYERS):\n","        # Layer normalization 1.\n","        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n","        # Create a multi-head attention layer.\n","        if not vanilla:\n","            attention_output = MultiHeadAttentionLSA(\n","                num_heads=NUM_HEADS, key_dim=PROJECTION_DIM, dropout=0.1\n","            )(x1, x1)\n","        else:\n","            attention_output = layers.MultiHeadAttention(\n","                num_heads=NUM_HEADS, key_dim=PROJECTION_DIM, dropout=0.1\n","            )(x1, x1)\n","        # Skip connection 1.\n","        x2 = layers.Add()([attention_output, encoded_patches])\n","        # Layer normalization 2.\n","        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n","        # MLP.\n","        x3 = mlp(x3, hidden_units=TRANSFORMER_UNITS, dropout_rate=0.1)\n","        # Skip connection 2.\n","        encoded_patches = layers.Add()([x3, x2])\n","\n","    # Create a [batch_size, projection_dim] tensor.\n","    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n","    representation = layers.Flatten()(representation)\n","    representation = layers.Dropout(0.5)(representation)\n","    # Add MLP.\n","    features = mlp(representation, hidden_units=MLP_HEAD_UNITS, dropout_rate=0.5)\n","    # Classify outputs.\n","    logits = layers.Dense(NUM_CLASSES, name=\"output_dense\")(features)\n","    # Create the Keras model.\n","    model = keras.Model(inputs=inputs, outputs=logits)\n","    return model"]},{"cell_type":"code","execution_count":70,"metadata":{"execution":{"iopub.execute_input":"2022-07-06T08:30:15.572705Z","iopub.status.busy":"2022-07-06T08:30:15.571313Z","iopub.status.idle":"2022-07-06T08:30:15.583558Z","shell.execute_reply":"2022-07-06T08:30:15.582104Z","shell.execute_reply.started":"2022-07-06T08:30:15.572658Z"},"trusted":true},"outputs":[],"source":["class WarmUpCosine(keras.optimizers.schedules.LearningRateSchedule):\n","    def __init__(\n","        self, learning_rate_base, total_steps, warmup_learning_rate, warmup_steps\n","    ):\n","        super(WarmUpCosine, self).__init__()\n","\n","        self.learning_rate_base = learning_rate_base\n","        self.total_steps = total_steps\n","        self.warmup_learning_rate = warmup_learning_rate\n","        self.warmup_steps = warmup_steps\n","        self.pi = tf.constant(np.pi)\n","\n","    def __call__(self, step):\n","        if self.total_steps < self.warmup_steps:\n","            raise ValueError(\"Total_steps must be larger or equal to warmup_steps.\")\n","\n","        cos_annealed_lr = tf.cos(\n","            self.pi\n","            * (tf.cast(step, tf.float32) - self.warmup_steps)\n","            / float(self.total_steps - self.warmup_steps)\n","        )\n","        learning_rate = 0.5 * self.learning_rate_base * (1 + cos_annealed_lr)\n","\n","        if self.warmup_steps > 0:\n","            if self.learning_rate_base < self.warmup_learning_rate:\n","                raise ValueError(\n","                    \"Learning_rate_base must be larger or equal to \"\n","                    \"warmup_learning_rate.\"\n","                )\n","            slope = (\n","                self.learning_rate_base - self.warmup_learning_rate\n","            ) / self.warmup_steps\n","            warmup_rate = slope * tf.cast(step, tf.float32) + self.warmup_learning_rate\n","            learning_rate = tf.where(\n","                step < self.warmup_steps, warmup_rate, learning_rate\n","            )\n","        return tf.where(\n","            step > self.total_steps, 0.0, learning_rate, name=\"learning_rate\"\n","        )"]},{"cell_type":"code","execution_count":71,"metadata":{"execution":{"iopub.execute_input":"2022-07-06T08:30:19.352798Z","iopub.status.busy":"2022-07-06T08:30:19.351958Z","iopub.status.idle":"2022-07-06T08:30:19.360959Z","shell.execute_reply":"2022-07-06T08:30:19.359640Z","shell.execute_reply.started":"2022-07-06T08:30:19.352761Z"},"trusted":true},"outputs":[],"source":["def run_experiment(model):\n","    total_steps = int((len(x_train) / BATCH_SIZE) * EPOCHS)\n","    warmup_epoch_percentage = 0.10\n","    warmup_steps = int(total_steps * warmup_epoch_percentage)\n","    scheduled_lrs = WarmUpCosine(\n","        learning_rate_base=LEARNING_RATE,\n","        total_steps=total_steps,\n","        warmup_learning_rate=0.0,\n","        warmup_steps=warmup_steps,\n","    )\n","    \n","    optimizer = tfa.optimizers.AdamW(\n","        learning_rate=LEARNING_RATE, weight_decay=WEIGHT_DECAY\n","    )\n","\n","    model.compile(\n","        optimizer=optimizer,\n","        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","        metrics=[\n","            keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n","            keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n","        ],\n","    )\n","\n","    history = model.fit(\n","        train_ds,\n","        epochs=EPOCHS\n","    )\n","    _, accuracy, top_5_accuracy = model.evaluate(test_ds)\n","    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n","    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n","\n","    return history"]},{"cell_type":"code","execution_count":74,"metadata":{"execution":{"iopub.execute_input":"2022-07-06T08:38:09.821227Z","iopub.status.busy":"2022-07-06T08:38:09.820626Z","iopub.status.idle":"2022-07-06T09:05:21.919573Z","shell.execute_reply":"2022-07-06T09:05:21.918343Z","shell.execute_reply.started":"2022-07-06T08:38:09.821178Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","25/25 [==============================] - 175s 6s/step - loss: 2.8382 - accuracy: 0.4362 - top-5-accuracy: 1.0000\n","Epoch 2/10\n","25/25 [==============================] - 159s 6s/step - loss: 0.9163 - accuracy: 0.6275 - top-5-accuracy: 1.0000\n","Epoch 3/10\n","25/25 [==============================] - 160s 6s/step - loss: 0.7830 - accuracy: 0.6867 - top-5-accuracy: 1.0000\n","Epoch 4/10\n","25/25 [==============================] - 160s 6s/step - loss: 0.7097 - accuracy: 0.7103 - top-5-accuracy: 1.0000\n","Epoch 5/10\n","25/25 [==============================] - 162s 6s/step - loss: 0.6518 - accuracy: 0.7347 - top-5-accuracy: 1.0000\n","Epoch 6/10\n","25/25 [==============================] - 161s 6s/step - loss: 0.6323 - accuracy: 0.7437 - top-5-accuracy: 1.0000\n","Epoch 7/10\n","25/25 [==============================] - 160s 6s/step - loss: 0.6060 - accuracy: 0.7530 - top-5-accuracy: 1.0000\n","Epoch 8/10\n","25/25 [==============================] - 160s 6s/step - loss: 0.5709 - accuracy: 0.7614 - top-5-accuracy: 1.0000\n","Epoch 9/10\n","25/25 [==============================] - 161s 6s/step - loss: 0.5295 - accuracy: 0.7812 - top-5-accuracy: 1.0000\n","Epoch 10/10\n","25/25 [==============================] - 160s 6s/step - loss: 0.5064 - accuracy: 0.8003 - top-5-accuracy: 1.0000\n","3/3 [==============================] - 8s 2s/step - loss: 0.4176 - accuracy: 0.8407 - top-5-accuracy: 1.0000\n","Test accuracy: 84.07%\n","Test top 5 accuracy: 100.0%\n"]}],"source":["vit_sl = create_vit_classifier(vanilla=False)\n","history = run_experiment(vit_sl)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
